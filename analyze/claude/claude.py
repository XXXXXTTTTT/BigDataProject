import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import json
import csv  # æ·»åŠ csvåº“
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œæ ·å¼
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
sns.set_style("whitegrid")
sns.set_palette("husl")
plt.rcParams['font.sans-serif'] = ['SimHei']  # ä½¿ç”¨é»‘ä½“
plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜

class BilibiliVideoAnalyzer:
    
    def __init__(self, csv_file_path=None):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        """
        self.df = None
        self.processed_data = {}
        
        if csv_file_path:
            self.load_data(csv_file_path)
        else:
            # ä½¿ç”¨æµ‹è¯•æ•°æ®
            self.create_test_data()
    
    def load_data(self, file_path):
        """
        ä½¿ç”¨csvåº“åŠ è½½CSVæ•°æ®
        """
        try:
            data_list = []
            with open(file_path, 'r', encoding='utf-8', newline='') as csvfile:
                # å°è¯•è‡ªåŠ¨æ£€æµ‹åˆ†éš”ç¬¦
                sample = csvfile.read(1024)
                csvfile.seek(0)
                
                # æ£€æµ‹åˆ†éš”ç¬¦
                sniffer = csv.Sniffer()
                delimiter = sniffer.sniff(sample).delimiter
                
                # å¦‚æœæ£€æµ‹å¤±è´¥ï¼Œé»˜è®¤ä½¿ç”¨åˆ¶è¡¨ç¬¦ï¼ˆæ ¹æ®åŸä»£ç ï¼‰
                if delimiter not in [',', '\t', ';', '|']:
                    delimiter = '\t'
                
                # è¯»å–CSVæ–‡ä»¶
                csv_reader = csv.DictReader(csvfile, delimiter=delimiter)
                
                for row in csv_reader:
                    # å¤„ç†æ•°å€¼å­—æ®µï¼Œå°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºé€‚å½“çš„æ•°æ®ç±»å‹
                    processed_row = {}
                    for key, value in row.items():
                        if value == '' or value is None:
                            processed_row[key] = None
                        else:
                            # å°è¯•è½¬æ¢æ•°å€¼å­—æ®µ
                            if key in ['timestamp', 'aid', 'videos', 'tid', 'copyright', 'pubdate', 'ctime', 
                                     'state', 'duration', 'stat_view', 'stat_danmaku', 'stat_reply', 
                                     'stat_favorite', 'stat_coin', 'stat_share', 'stat_now_rank', 
                                     'stat_his_rank', 'stat_like', 'stat_dislike', 'stat_vt', 
                                     'stat_vv', 'stat_fav_g', 'stat_like_g', 'owner_mid']:
                                try:
                                    processed_row[key] = int(float(value))
                                except (ValueError, TypeError):
                                    processed_row[key] = value
                            else:
                                processed_row[key] = value
                    
                    data_list.append(processed_row)
            
            # è½¬æ¢ä¸ºDataFrame
            self.df = pd.DataFrame(data_list)
            print(f"æˆåŠŸä½¿ç”¨csvåº“åŠ è½½æ•°æ®ï¼Œå…± {len(self.df)} æ¡è®°å½•")
            
            # æ˜¾ç¤ºæ•°æ®åŸºæœ¬ä¿¡æ¯
            print(f"æ•°æ®åˆ—æ•°: {len(self.df.columns)}")
            print(f"ä¸»è¦åˆ—å: {list(self.df.columns[:10])}")
            
        except FileNotFoundError:
            print(f"æ–‡ä»¶ {file_path} æœªæ‰¾åˆ°ï¼Œä½¿ç”¨æµ‹è¯•æ•°æ®")
            self.create_test_data()
        except UnicodeDecodeError:
            print("æ–‡ä»¶ç¼–ç é”™è¯¯ï¼Œå°è¯•ä½¿ç”¨å…¶ä»–ç¼–ç æ ¼å¼...")
            try:
                # å°è¯•ä½¿ç”¨å…¶ä»–ç¼–ç 
                self.load_data_with_encoding(file_path, 'gbk')
            except:
                print("ç¼–ç è½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨æµ‹è¯•æ•°æ®")
                self.create_test_data()
        except Exception as e:
            print(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
            print("ä½¿ç”¨æµ‹è¯•æ•°æ®ç»§ç»­åˆ†æ")
            self.create_test_data()
    
    def load_data_with_encoding(self, file_path, encoding):
        """
        ä½¿ç”¨æŒ‡å®šç¼–ç åŠ è½½æ•°æ®
        """
        data_list = []
        with open(file_path, 'r', encoding=encoding, newline='') as csvfile:
            # æ£€æµ‹åˆ†éš”ç¬¦
            sample = csvfile.read(1024)
            csvfile.seek(0)
            
            sniffer = csv.Sniffer()
            try:
                delimiter = sniffer.sniff(sample).delimiter
            except:
                delimiter = '\t'  # é»˜è®¤ä½¿ç”¨åˆ¶è¡¨ç¬¦
            
            csv_reader = csv.DictReader(csvfile, delimiter=delimiter)
            
            for row in csv_reader:
                processed_row = {}
                for key, value in row.items():
                    if value == '' or value is None:
                        processed_row[key] = None
                    else:
                        # æ•°å€¼å­—æ®µè½¬æ¢
                        if key in ['timestamp', 'aid', 'videos', 'tid', 'copyright', 'pubdate', 'ctime', 
                                 'state', 'duration', 'stat_view', 'stat_danmaku', 'stat_reply', 
                                 'stat_favorite', 'stat_coin', 'stat_share', 'stat_now_rank', 
                                 'stat_his_rank', 'stat_like', 'stat_dislike', 'stat_vt', 
                                 'stat_vv', 'stat_fav_g', 'stat_like_g', 'owner_mid']:
                            try:
                                processed_row[key] = int(float(value))
                            except (ValueError, TypeError):
                                processed_row[key] = value
                        else:
                            processed_row[key] = value
                
                data_list.append(processed_row)
        
        self.df = pd.DataFrame(data_list)
        print(f"æˆåŠŸä½¿ç”¨ {encoding} ç¼–ç åŠ è½½æ•°æ®ï¼Œå…± {len(self.df)} æ¡è®°å½•")
    
    def preprocess_data(self):
        """
        æ•°æ®é¢„å¤„ç†
        """
        print("å¼€å§‹æ•°æ®é¢„å¤„ç†...")
        
        # è½¬æ¢æ—¶é—´æˆ³
        self.df['datetime'] = pd.to_datetime(self.df['timestamp'], unit='s')
        self.df['pubdate_dt'] = pd.to_datetime(self.df['pubdate'], unit='s')
        self.df['hour'] = self.df['datetime'].dt.hour
        self.df['day_of_week'] = self.df['datetime'].dt.dayofweek
        self.df['date'] = self.df['datetime'].dt.date
        
        # å¤„ç†æ ‡ç­¾
        self.df['tags_list'] = self.df['tags'].str.split(',')
        self.df['tags_count'] = self.df['tags_list'].apply(lambda x: len(x) if isinstance(x, list) else 0)
        
        # è®¡ç®—äº’åŠ¨ç‡
        self.df['engagement_rate'] = (
            self.df['stat_like'] + self.df['stat_coin'] + self.df['stat_favorite'] + 
            self.df['stat_share'] + self.df['stat_reply']
        ) / self.df['stat_view']
        
        # è®¡ç®—è§†é¢‘è´¨é‡åˆ†æ•°ï¼ˆç»¼åˆæŒ‡æ ‡ï¼‰
        self.df['quality_score'] = (
            self.df['stat_like'] * 0.3 + 
            self.df['stat_coin'] * 0.2 + 
            self.df['stat_favorite'] * 0.2 + 
            self.df['stat_share'] * 0.15 + 
            self.df['stat_reply'] * 0.15
        ) / self.df['stat_view']
        
        # æ—¶é•¿åˆ†ç±»
        self.df['duration_category'] = pd.cut(
            self.df['duration'], 
            bins=[0, 60, 300, 600, 1800, float('inf')], 
            labels=['çŸ­è§†é¢‘(<1min)', 'çŸ­ä¸­è§†é¢‘(1-5min)', 'ä¸­ç­‰è§†é¢‘(5-10min)', 'é•¿è§†é¢‘(10-30min)', 'è¶…é•¿è§†é¢‘(>30min)']
        )
        
        print("æ•°æ®é¢„å¤„ç†å®Œæˆ")
    
    def analyze_time_activity(self):
        """
        åˆ†æç”¨æˆ·æ´»è·ƒæ—¶æ®µ
        """
        print("åˆ†æç”¨æˆ·æ´»è·ƒæ—¶æ®µ...")
        
        # æŒ‰å°æ—¶ç»Ÿè®¡è§‚çœ‹é‡
        hourly_views = self.df.groupby('hour').agg({
            'stat_view': ['sum', 'mean', 'count'],
            'stat_like': 'sum',
            'stat_reply': 'sum',
            'stat_share': 'sum'
        }).round(2)
        
        # æŒ‰æ˜ŸæœŸå‡ ç»Ÿè®¡
        weekday_views = self.df.groupby('day_of_week').agg({
            'stat_view': ['sum', 'mean', 'count'],
            'stat_like': 'sum',
            'engagement_rate': 'mean'
        }).round(2)
        
        # æŒ‰æ—¥æœŸç»Ÿè®¡ï¼ˆè¶‹åŠ¿åˆ†æï¼‰
        daily_views = self.df.groupby('date').agg({
            'stat_view': 'sum',
            'aid': 'nunique',  # æ¯æ—¥çƒ­é—¨è§†é¢‘æ•°é‡
            'engagement_rate': 'mean'
        }).round(2)
        
        self.processed_data['hourly_activity'] = hourly_views
        self.processed_data['weekday_activity'] = weekday_views
        self.processed_data['daily_trends'] = daily_views
        
        return hourly_views, weekday_views, daily_views
    
    def analyze_video_characteristics(self):
        """
        åˆ†æè§†é¢‘ç‰¹å¾
        """
        print("åˆ†æè§†é¢‘ç‰¹å¾...")
        
        # æŒ‰åˆ†åŒºåˆ†æ
        category_analysis = self.df.groupby('tnamev2').agg({
            'stat_view': ['mean', 'sum', 'count'],
            'stat_like': 'mean',
            'engagement_rate': 'mean',
            'duration': 'mean',
            'quality_score': 'mean'
        }).round(2)
        
        # æŒ‰æ—¶é•¿åˆ†æ
        duration_analysis = self.df.groupby('duration_category').agg({
            'stat_view': ['mean', 'count'],
            'engagement_rate': 'mean',
            'quality_score': 'mean'
        }).round(2)
        
        # UPä¸»åˆ†æ
        owner_analysis = self.df.groupby('owner_name').agg({
            'stat_view': ['sum', 'mean', 'count'],
            'engagement_rate': 'mean',
            'quality_score': 'mean'
        }).round(2)
        
        # æ ‡ç­¾åˆ†æ
        all_tags = []
        for tags_list in self.df['tags_list'].dropna():
            if isinstance(tags_list, list):
                all_tags.extend([tag.strip() for tag in tags_list if tag.strip()])
        
        tag_counts = pd.Series(all_tags).value_counts().head(20)
        
        self.processed_data['category_analysis'] = category_analysis
        self.processed_data['duration_analysis'] = duration_analysis
        self.processed_data['owner_analysis'] = owner_analysis
        self.processed_data['popular_tags'] = tag_counts
        
        return category_analysis, duration_analysis, owner_analysis, tag_counts
    
    def create_visualizations(self):
        print("åˆ›å»ºå¯è§†åŒ–å›¾è¡¨...")
        
        # è®¾ç½®å…¨å±€æ ·å¼
        plt.rcParams['font.size'] = 12
        
        # 1. 24å°æ—¶æ´»è·ƒåº¦åˆ†æ
        plt.figure(figsize=(12, 6))
        hourly_data = self.processed_data['hourly_activity']['stat_view']['sum']
        full_hourly = pd.Series(0, index=range(24))
        full_hourly.update(hourly_data)
        
        bars1 = plt.bar(range(24), full_hourly.values, color='skyblue', alpha=0.8)
        plt.title('24å°æ—¶ç”¨æˆ·æ´»è·ƒåº¦åˆ†å¸ƒ', fontsize=16, fontweight='bold')
        plt.xlabel('å°æ—¶', fontsize=12)
        plt.ylabel('æ€»è§‚çœ‹é‡', fontsize=12)
        plt.xticks(range(0, 24, 2))
        plt.grid(True, alpha=0.3)
        
        for bar in bars1:
            height = bar.get_height()
            if not pd.isna(height) and height > 0:
                plt.text(bar.get_x() + bar.get_width()/2., height,
                        f'{int(height/1000)}K' if height > 1000 else f'{int(height)}',
                        ha='center', va='bottom', fontsize=10)
        
        plt.tight_layout()
        plt.savefig('01_24å°æ—¶æ´»è·ƒåº¦åˆ†å¸ƒ.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 2. ä¸€å‘¨æ´»è·ƒåº¦åˆ†æ
        plt.figure(figsize=(10, 6))
        weekday_names = ['å‘¨ä¸€', 'å‘¨äºŒ', 'å‘¨ä¸‰', 'å‘¨å››', 'å‘¨äº”', 'å‘¨å…­', 'å‘¨æ—¥']
        weekday_data = self.processed_data['weekday_activity']['stat_view']['sum']
        full_weekday = pd.Series(0, index=range(7))
        full_weekday.update(weekday_data)
        
        bars2 = plt.bar(weekday_names, full_weekday.values, color='lightcoral', alpha=0.8)
        plt.title('ä¸€å‘¨ç”¨æˆ·æ´»è·ƒåº¦åˆ†å¸ƒ', fontsize=16, fontweight='bold')
        plt.xlabel('æ˜ŸæœŸ', fontsize=12)
        plt.ylabel('æ€»è§‚çœ‹é‡', fontsize=12)
        plt.grid(True, alpha=0.3)
        
        for bar in bars2:
            height = bar.get_height()
            if not pd.isna(height) and height > 0:
                plt.text(bar.get_x() + bar.get_width()/2., height,
                        f'{int(height/1000)}K' if height > 1000 else f'{int(height)}',
                        ha='center', va='bottom', fontsize=10)
        
        plt.tight_layout()
        plt.savefig('02_ä¸€å‘¨æ´»è·ƒåº¦åˆ†å¸ƒ.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 3. è§†é¢‘åˆ†åŒºå¯¹æ¯”
        plt.figure(figsize=(12, 8))
        category_data = self.processed_data['category_analysis']['stat_view']['mean'].head(10)
        if len(category_data) > 0:
            bars3 = plt.barh(range(len(category_data)), category_data.values, color='lightgreen', alpha=0.8)
            plt.title('å„åˆ†åŒºå¹³å‡è§‚çœ‹é‡å¯¹æ¯”', fontsize=16, fontweight='bold')
            plt.xlabel('å¹³å‡è§‚çœ‹é‡', fontsize=12)
            plt.yticks(range(len(category_data)), category_data.index)
            plt.grid(True, alpha=0.3, axis='x')
            
            for i, bar in enumerate(bars3):
                width = bar.get_width()
                if not pd.isna(width) and width > 0:
                    plt.text(width, bar.get_y() + bar.get_height()/2.,
                            f'{int(width/1000)}K' if width > 1000 else f'{int(width)}',
                            ha='left', va='center', fontsize=10)
        else:
            plt.text(0.5, 0.5, 'æ•°æ®ä¸è¶³', ha='center', va='center', transform=plt.gca().transAxes, fontsize=14)
            plt.title('å„åˆ†åŒºå¹³å‡è§‚çœ‹é‡å¯¹æ¯”', fontsize=16, fontweight='bold')
        
        plt.tight_layout()
        plt.savefig('03_å„åˆ†åŒºå¹³å‡è§‚çœ‹é‡å¯¹æ¯”.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 4. äº’åŠ¨ç‡vsè§‚çœ‹é‡æ•£ç‚¹å›¾
        plt.figure(figsize=(10, 8))
        if len(self.df) > 0:
            scatter = plt.scatter(self.df['stat_view'], self.df['engagement_rate'], 
                                c=self.df['duration'], cmap='viridis', alpha=0.6, s=50)
            plt.title('è§‚çœ‹é‡vsäº’åŠ¨ç‡å…³ç³»', fontsize=16, fontweight='bold')
            plt.xlabel('è§‚çœ‹é‡', fontsize=12)
            plt.ylabel('äº’åŠ¨ç‡', fontsize=12)
            plt.colorbar(scatter, label='è§†é¢‘æ—¶é•¿(ç§’)')
            plt.grid(True, alpha=0.3)
            if self.df['stat_view'].min() > 0:
                plt.xscale('log')
        
        plt.tight_layout()
        plt.savefig('04_è§‚çœ‹é‡vsäº’åŠ¨ç‡å…³ç³».png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 5. è§†é¢‘æ—¶é•¿åˆ†å¸ƒ
        plt.figure(figsize=(12, 6))
        duration_data = self.processed_data['duration_analysis']['stat_view']['mean']
        if len(duration_data) > 0:
            bars5 = plt.bar(range(len(duration_data)), duration_data.values, color='orange', alpha=0.8)
            plt.title('ä¸åŒæ—¶é•¿è§†é¢‘å¹³å‡è§‚çœ‹é‡', fontsize=16, fontweight='bold')
            plt.xlabel('è§†é¢‘æ—¶é•¿åˆ†ç±»', fontsize=12)
            plt.ylabel('å¹³å‡è§‚çœ‹é‡', fontsize=12)
            plt.xticks(range(len(duration_data)), duration_data.index, rotation=45)
            plt.grid(True, alpha=0.3)
            
            for bar in bars5:
                height = bar.get_height()
                if not pd.isna(height) and height > 0:
                    plt.text(bar.get_x() + bar.get_width()/2., height,
                            f'{int(height/1000)}K' if height > 1000 else f'{int(height)}',
                            ha='center', va='bottom', fontsize=10)
        else:
            plt.text(0.5, 0.5, 'æ•°æ®ä¸è¶³', ha='center', va='center', transform=plt.gca().transAxes, fontsize=14)
            plt.title('ä¸åŒæ—¶é•¿è§†é¢‘å¹³å‡è§‚çœ‹é‡', fontsize=16, fontweight='bold')
        
        plt.tight_layout()
        plt.savefig('05_ä¸åŒæ—¶é•¿è§†é¢‘å¹³å‡è§‚çœ‹é‡.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 6. çƒ­é—¨æ ‡ç­¾TOP15
        plt.figure(figsize=(12, 8))
        top_tags = self.processed_data['popular_tags'].head(15)
        if len(top_tags) > 0:
            bars6 = plt.barh(range(len(top_tags)), top_tags.values, color='purple', alpha=0.7)
            plt.title('çƒ­é—¨æ ‡ç­¾TOP15', fontsize=16, fontweight='bold')
            plt.xlabel('å‡ºç°æ¬¡æ•°', fontsize=12)
            plt.yticks(range(len(top_tags)), top_tags.index)
            plt.grid(True, alpha=0.3, axis='x')
            
            for i, bar in enumerate(bars6):
                width = bar.get_width()
                if not pd.isna(width) and width > 0:
                    plt.text(width, bar.get_y() + bar.get_height()/2.,
                            f'{int(width)}', ha='left', va='center', fontsize=10)
        else:
            plt.text(0.5, 0.5, 'æ ‡ç­¾æ•°æ®ä¸è¶³', ha='center', va='center', transform=plt.gca().transAxes, fontsize=14)
            plt.title('çƒ­é—¨æ ‡ç­¾TOP15', fontsize=16, fontweight='bold')
        
        plt.tight_layout()
        plt.savefig('06_çƒ­é—¨æ ‡ç­¾TOP15.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 7. è´¨é‡åˆ†æ•°åˆ†å¸ƒ
        plt.figure(figsize=(10, 6))
        if len(self.df) > 0 and not self.df['quality_score'].isna().all():
            plt.hist(self.df['quality_score'].dropna(), bins=min(30, len(self.df)), 
                    color='teal', alpha=0.7, edgecolor='black')
            plt.title('è§†é¢‘è´¨é‡åˆ†æ•°åˆ†å¸ƒ', fontsize=16, fontweight='bold')
            plt.xlabel('è´¨é‡åˆ†æ•°', fontsize=12)
            plt.ylabel('è§†é¢‘æ•°é‡', fontsize=12)
            plt.grid(True, alpha=0.3)
        else:
            plt.text(0.5, 0.5, 'è´¨é‡åˆ†æ•°æ•°æ®ä¸è¶³', ha='center', va='center', transform=plt.gca().transAxes, fontsize=14)
            plt.title('è§†é¢‘è´¨é‡åˆ†æ•°åˆ†å¸ƒ', fontsize=16, fontweight='bold')
        
        plt.tight_layout()
        plt.savefig('07_è§†é¢‘è´¨é‡åˆ†æ•°åˆ†å¸ƒ.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 8. æ—¶é•¿vsäº’åŠ¨ç‡ç®±çº¿å›¾
        plt.figure(figsize=(12, 6))
        if len(self.df) > 0 and not self.df['duration_category'].isna().all():
            try:
                sns.boxplot(data=self.df, x='duration_category', y='engagement_rate')
                plt.title('ä¸åŒæ—¶é•¿è§†é¢‘äº’åŠ¨ç‡åˆ†å¸ƒ', fontsize=16, fontweight='bold')
                plt.xlabel('è§†é¢‘æ—¶é•¿åˆ†ç±»', fontsize=12)
                plt.ylabel('äº’åŠ¨ç‡', fontsize=12)
                plt.xticks(rotation=45)
                plt.grid(True, alpha=0.3)
            except:
                plt.text(0.5, 0.5, 'æ•°æ®ä¸è¶³ç»˜åˆ¶ç®±çº¿å›¾', ha='center', va='center', transform=plt.gca().transAxes, fontsize=14)
                plt.title('ä¸åŒæ—¶é•¿è§†é¢‘äº’åŠ¨ç‡åˆ†å¸ƒ', fontsize=16, fontweight='bold')
        else:
            plt.text(0.5, 0.5, 'æ—¶é•¿åˆ†ç±»æ•°æ®ä¸è¶³', ha='center', va='center', transform=plt.gca().transAxes, fontsize=14)
            plt.title('ä¸åŒæ—¶é•¿è§†é¢‘äº’åŠ¨ç‡åˆ†å¸ƒ', fontsize=16, fontweight='bold')
        
        plt.tight_layout()
        plt.savefig('08_ä¸åŒæ—¶é•¿è§†é¢‘äº’åŠ¨ç‡åˆ†å¸ƒ.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 9. è§‚çœ‹é‡vsç‚¹èµé‡å…³ç³»
        plt.figure(figsize=(10, 8))
        if len(self.df) > 0:
            plt.scatter(self.df['stat_view'], self.df['stat_like'], alpha=0.6, color='red', s=30)
            plt.title('è§‚çœ‹é‡vsç‚¹èµé‡å…³ç³»', fontsize=16, fontweight='bold')
            plt.xlabel('è§‚çœ‹é‡', fontsize=12)
            plt.ylabel('ç‚¹èµé‡', fontsize=12)
            plt.grid(True, alpha=0.3)
            
            if self.df['stat_view'].min() > 0 and self.df['stat_like'].min() > 0:
                plt.xscale('log')
                plt.yscale('log')
                
                # æ·»åŠ è¶‹åŠ¿çº¿
                try:
                    z = np.polyfit(np.log(self.df['stat_view']), np.log(self.df['stat_like']), 1)
                    p = np.poly1d(z)
                    plt.plot(self.df['stat_view'], np.exp(p(np.log(self.df['stat_view']))), 
                            "orange", alpha=0.8, linewidth=2, label='è¶‹åŠ¿çº¿')
                    plt.legend()
                except:
                    pass
        
        plt.tight_layout()
        plt.savefig('09_è§‚çœ‹é‡vsç‚¹èµé‡å…³ç³».png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 10. æ¯å°æ—¶å¹³å‡äº’åŠ¨ç‡
        plt.figure(figsize=(12, 6))
        hourly_engagement = self.df.groupby('hour')['engagement_rate'].mean()
        full_hourly_engagement = pd.Series(0, index=range(24))
        full_hourly_engagement.update(hourly_engagement)
        
        plt.plot(range(24), full_hourly_engagement.values, marker='o', linewidth=2, 
                markersize=8, color='green', markerfacecolor='lightgreen', markeredgecolor='darkgreen')
        plt.title('24å°æ—¶å¹³å‡äº’åŠ¨ç‡å˜åŒ–', fontsize=16, fontweight='bold')
        plt.xlabel('å°æ—¶', fontsize=12)
        plt.ylabel('å¹³å‡äº’åŠ¨ç‡', fontsize=12)
        plt.xticks(range(0, 24, 2))
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('10_24å°æ—¶å¹³å‡äº’åŠ¨ç‡å˜åŒ–.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 11. UPä¸»è§†é¢‘æ•°é‡vsè´¨é‡
        plt.figure(figsize=(10, 8))
        if len(self.df) > 0:
            owner_stats = self.df.groupby('owner_name').agg({
                'aid': 'count',
                'quality_score': 'mean'
            })
            if len(owner_stats) > 0:
                plt.scatter(owner_stats['aid'], owner_stats['quality_score'], 
                        alpha=0.7, s=80, color='brown')
                plt.title('UPä¸»è§†é¢‘æ•°é‡vså¹³å‡è´¨é‡', fontsize=16, fontweight='bold')
                plt.xlabel('è§†é¢‘æ•°é‡', fontsize=12)
                plt.ylabel('å¹³å‡è´¨é‡åˆ†æ•°', fontsize=12)
                plt.grid(True, alpha=0.3)
            else:
                plt.text(0.5, 0.5, 'UPä¸»æ•°æ®ä¸è¶³', ha='center', va='center', transform=plt.gca().transAxes, fontsize=14)
                plt.title('UPä¸»è§†é¢‘æ•°é‡vså¹³å‡è´¨é‡', fontsize=16, fontweight='bold')
        
        plt.tight_layout()
        plt.savefig('11_UPä¸»è§†é¢‘æ•°é‡vså¹³å‡è´¨é‡.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 12. åˆ†åŒºäº’åŠ¨ç‡å¯¹æ¯”
        plt.figure(figsize=(12, 8))
        category_engagement = self.processed_data['category_analysis']['engagement_rate']['mean'].head(8)
        if len(category_engagement) > 0:
            bars12 = plt.bar(range(len(category_engagement)), category_engagement.values, 
                            color='navy', alpha=0.8)
            plt.title('å„åˆ†åŒºå¹³å‡äº’åŠ¨ç‡å¯¹æ¯”', fontsize=16, fontweight='bold')
            plt.xlabel('åˆ†åŒº', fontsize=12)
            plt.ylabel('å¹³å‡äº’åŠ¨ç‡', fontsize=12)
            plt.xticks(range(len(category_engagement)), category_engagement.index, rotation=45)
            plt.grid(True, alpha=0.3)
            
            for bar in bars12:
                height = bar.get_height()
                if not pd.isna(height) and height > 0:
                    plt.text(bar.get_x() + bar.get_width()/2., height,
                            f'{height:.3f}', ha='center', va='bottom', fontsize=10)
        else:
            plt.text(0.5, 0.5, 'åˆ†åŒºæ•°æ®ä¸è¶³', ha='center', va='center', transform=plt.gca().transAxes, fontsize=14)
            plt.title('å„åˆ†åŒºå¹³å‡äº’åŠ¨ç‡å¯¹æ¯”', fontsize=16, fontweight='bold')
        
        plt.tight_layout()
        plt.savefig('12_å„åˆ†åŒºå¹³å‡äº’åŠ¨ç‡å¯¹æ¯”.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print("æ‰€æœ‰å›¾è¡¨å·²å•ç‹¬ä¿å­˜å®Œæˆï¼")
        print("ç”Ÿæˆçš„å›¾è¡¨æ–‡ä»¶ï¼š")
        for i in range(1, 13):
            filename_map = {
                1: "01_24å°æ—¶æ´»è·ƒåº¦åˆ†å¸ƒ.png",
                2: "02_ä¸€å‘¨æ´»è·ƒåº¦åˆ†å¸ƒ.png", 
                3: "03_å„åˆ†åŒºå¹³å‡è§‚çœ‹é‡å¯¹æ¯”.png",
                4: "04_è§‚çœ‹é‡vsäº’åŠ¨ç‡å…³ç³».png",
                5: "05_ä¸åŒæ—¶é•¿è§†é¢‘å¹³å‡è§‚çœ‹é‡.png",
                6: "06_çƒ­é—¨æ ‡ç­¾TOP15.png",
                7: "07_è§†é¢‘è´¨é‡åˆ†æ•°åˆ†å¸ƒ.png",
                8: "08_ä¸åŒæ—¶é•¿è§†é¢‘äº’åŠ¨ç‡åˆ†å¸ƒ.png",
                9: "09_è§‚çœ‹é‡vsç‚¹èµé‡å…³ç³».png",
                10: "10_24å°æ—¶å¹³å‡äº’åŠ¨ç‡å˜åŒ–.png",
                11: "11_UPä¸»è§†é¢‘æ•°é‡vså¹³å‡è´¨é‡.png",
                12: "12_å„åˆ†åŒºå¹³å‡äº’åŠ¨ç‡å¯¹æ¯”.png"
            }
            print(f"- {filename_map[i]}")
    
    def export_analysis_results(self):
        """
        å¯¼å‡ºåˆ†æç»“æœåˆ°æ–‡ä»¶
        """
        print("å¯¼å‡ºåˆ†æç»“æœ...")
        
        # å¯¼å‡ºåˆ°Excel
        # with pd.ExcelWriter('bilibili_analysis_results.xlsx', engine='openpyxl') as writer:
            # åŸå§‹æ•°æ®
            # self.df.to_excel(writer, sheet_name='åŸå§‹æ•°æ®', index=False)
            
            # # æ—¶é—´æ´»è·ƒåº¦åˆ†æ
            # self.processed_data['hourly_activity'].to_excel(writer, sheet_name='24å°æ—¶æ´»è·ƒåº¦')
            # self.processed_data['weekday_activity'].to_excel(writer, sheet_name='ä¸€å‘¨æ´»è·ƒåº¦')
            
            # # è§†é¢‘ç‰¹å¾åˆ†æ
            # self.processed_data['category_analysis'].to_excel(writer, sheet_name='åˆ†åŒºåˆ†æ')
            # self.processed_data['duration_analysis'].to_excel(writer, sheet_name='æ—¶é•¿åˆ†æ')
            # self.processed_data['owner_analysis'].to_excel(writer, sheet_name='UPä¸»åˆ†æ')
            
            # # çƒ­é—¨æ ‡ç­¾
            # self.processed_data['popular_tags'].to_excel(writer, sheet_name='çƒ­é—¨æ ‡ç­¾')
        
        # å¯¼å‡ºJSONæ ¼å¼ï¼ˆç”¨äºå‰ç«¯å›¾è¡¨ï¼‰
        json_data = {
            'hourly_activity': {
                'hours': list(range(24)),
                'views': self.processed_data['hourly_activity']['stat_view']['sum'].tolist(),
                'engagement': self.df.groupby('hour')['engagement_rate'].mean().tolist()
            },
            'weekday_activity': {
                'days': ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'],
                'views': self.processed_data['weekday_activity']['stat_view']['sum'].tolist(),
                'engagement': self.processed_data['weekday_activity']['engagement_rate']['mean'].tolist()
            },
            'category_stats': {
                'categories': self.processed_data['category_analysis']['stat_view']['mean'].head(10).index.tolist(),
                'avg_views': self.processed_data['category_analysis']['stat_view']['mean'].head(10).tolist(),
                'engagement_rates': self.processed_data['category_analysis']['engagement_rate']['mean'].head(10).tolist()
            },
            'duration_stats': {
                'categories': self.processed_data['duration_analysis']['stat_view']['mean'].index.tolist(),
                'avg_views': self.processed_data['duration_analysis']['stat_view']['mean'].tolist(),
                'engagement_rates': self.processed_data['duration_analysis']['engagement_rate']['mean'].tolist()
            },
            'popular_tags': {
                'tags': self.processed_data['popular_tags'].head(20).index.tolist(),
                'counts': self.processed_data['popular_tags'].head(20).tolist()
            },
            'summary_stats': {
                'total_videos': len(self.df),
                'total_views': int(self.df['stat_view'].sum()),
                'avg_engagement': float(self.df['engagement_rate'].mean()),
                'peak_hour': int(self.processed_data['hourly_activity']['stat_view']['sum'].idxmax()),
                'most_active_day': int(self.processed_data['weekday_activity']['stat_view']['sum'].idxmax()),
                'top_category': self.processed_data['category_analysis']['stat_view']['sum'].idxmax()
            }
        }
        
        with open('bilibili_analysis_data.json', 'w', encoding='utf-8') as f:
            json.dump(json_data, f, ensure_ascii=False, indent=2)
        
        print("ç»“æœå·²å¯¼å‡ºåˆ°:")
        print("- bilibili_analysis_results.xlsx (è¯¦ç»†æ•°æ®)")
        print("- bilibili_analysis_data.json (å‰ç«¯å›¾è¡¨æ•°æ®)")
    
    def generate_insights_report(self):
        """
        ç”Ÿæˆæ´å¯ŸæŠ¥å‘Š
        """
        print("\n=== Bç«™çƒ­é—¨è§†é¢‘æ•°æ®åˆ†ææŠ¥å‘Š ===")
        
        # åŸºç¡€ç»Ÿè®¡
        total_videos = len(self.df)
        total_views = self.df['stat_view'].sum()
        avg_engagement = self.df['engagement_rate'].mean()
        
        print(f"\nğŸ“Š åŸºç¡€ç»Ÿè®¡:")
        print(f"â€¢ åˆ†æè§†é¢‘æ€»æ•°: {total_videos:,}")
        print(f"â€¢ æ€»è§‚çœ‹é‡: {total_views:,}")
        print(f"â€¢ å¹³å‡äº’åŠ¨ç‡: {avg_engagement:.4f}")
        
        # æ—¶é—´æ´»è·ƒåº¦æ´å¯Ÿ
        peak_hour = self.processed_data['hourly_activity']['stat_view']['sum'].idxmax()
        peak_views = self.processed_data['hourly_activity']['stat_view']['sum'].max()
        
        most_active_day = self.processed_data['weekday_activity']['stat_view']['sum'].idxmax()
        weekday_names = ['å‘¨ä¸€', 'å‘¨äºŒ', 'å‘¨ä¸‰', 'å‘¨å››', 'å‘¨äº”', 'å‘¨å…­', 'å‘¨æ—¥']
        
        print(f"\nâ° ç”¨æˆ·æ´»è·ƒæ—¶æ®µåˆ†æ:")
        print(f"â€¢ æœ€æ´»è·ƒæ—¶æ®µ: {peak_hour}:00 (è§‚çœ‹é‡: {peak_views:,})")
        print(f"â€¢ æœ€æ´»è·ƒæ—¥æœŸ: {weekday_names[most_active_day]}")
        
        # è§†é¢‘ç‰¹å¾æ´å¯Ÿ
        top_category = self.processed_data['category_analysis']['stat_view']['mean'].idxmax()
        top_category_views = self.processed_data['category_analysis']['stat_view']['mean'].max()
        
        best_duration = self.processed_data['duration_analysis']['engagement_rate']['mean'].idxmax()
        
        print(f"\nğŸ¬ è§†é¢‘ç‰¹å¾åˆ†æ:")
        print(f"â€¢ æœ€å—æ¬¢è¿åˆ†åŒº: {top_category} (å¹³å‡è§‚çœ‹é‡: {top_category_views:,.0f})")
        print(f"â€¢ æœ€ä½³è§†é¢‘æ—¶é•¿: {best_duration}")
        
        # çƒ­é—¨æ ‡ç­¾
        top_3_tags = self.processed_data['popular_tags'].head(3)
        print(f"\nğŸ·ï¸ çƒ­é—¨æ ‡ç­¾TOP3:")
        for i, (tag, count) in enumerate(top_3_tags.items(), 1):
            print(f"â€¢ {i}. {tag} ({count}æ¬¡)")
        
        # è´¨é‡åˆ†æ
        high_quality_threshold = self.df['quality_score'].quantile(0.8)
        high_quality_videos = self.df[self.df['quality_score'] >= high_quality_threshold]
        
        print(f"\nâ­ é«˜è´¨é‡è§†é¢‘ç‰¹å¾:")
        print(f"â€¢ é«˜è´¨é‡è§†é¢‘æ•°é‡: {len(high_quality_videos)} ({len(high_quality_videos)/total_videos*100:.1f}%)")
        print(f"â€¢ é«˜è´¨é‡è§†é¢‘å¹³å‡æ—¶é•¿: {high_quality_videos['duration'].mean():.0f}ç§’")
        print(f"â€¢ é«˜è´¨é‡è§†é¢‘ä¸»è¦åˆ†åŒº: {high_quality_videos['tnamev2'].mode().iloc[0]}")
        
        print("\n" + "="*50)
    
    def run_complete_analysis(self):
        """
        è¿è¡Œå®Œæ•´åˆ†ææµç¨‹
        """
        print("å¼€å§‹Bç«™çƒ­é—¨è§†é¢‘æ•°æ®åˆ†æ...")
        
        # æ•°æ®é¢„å¤„ç†
        self.preprocess_data()
        
        # æ‰§è¡Œåˆ†æ
        self.analyze_time_activity()
        self.analyze_video_characteristics()
        
        # åˆ›å»ºå¯è§†åŒ–
        self.create_visualizations()
        
        # å¯¼å‡ºç»“æœ
        self.export_analysis_results()
        
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_insights_report()
        
        print("\nâœ… åˆ†æå®Œæˆï¼æ‰€æœ‰æ–‡ä»¶å·²ç”Ÿæˆã€‚")

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":

    # å¦‚æœæœ‰CSVæ–‡ä»¶ï¼Œå¯ä»¥è¿™æ ·åŠ è½½ï¼š
    analyzer = BilibiliVideoAnalyzer('video_data.csv')
    
    # è¿è¡Œå®Œæ•´åˆ†æ
    analyzer.run_complete_analysis()